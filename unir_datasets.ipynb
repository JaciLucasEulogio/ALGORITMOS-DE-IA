{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para Unir los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instala pandas\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer modelo\n",
    "Cantidad de datos: 166475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de postulante leído correctamente\n",
      "Archivo de educación leído correctamente\n",
      "Archivo de discapacidad leído correctamente\n",
      "                      ID_POSTULANTE                           EMPRESA  \\\n",
      "0  03AFDBD66E7929B125F8597834FA83A4  AAB3DD1AA8AF62CB516EE8C9AEEB0B35   \n",
      "1  03AFDBD66E7929B125F8597834FA83A4  AAB3DD1AA8AF62CB516EE8C9AEEB0B35   \n",
      "2  EA5D2F1C4608232E07D3AA3D998E5135  89C9A87CE323B6A3086D15356D3DB2BA   \n",
      "3  EA5D2F1C4608232E07D3AA3D998E5135  89C9A87CE323B6A3086D15356D3DB2BA   \n",
      "4  FC490CA45C00B1249BBE3554A4FDF6FB  8EAC8447385B013E2A83BAAAB6B47F35   \n",
      "\n",
      "   FECHAINICIO    FECHAFIN                                        DESCRIPCION  \\\n",
      "0   20200301.0  20210701.0  capacitar a miembros de mesa, fuerzas armadas ...   \n",
      "1   20200301.0  20210701.0  capacitar a miembros de mesa, fuerzas armadas ...   \n",
      "2   20190601.0  20200901.0  ValorizaciÃ³n de los trabajos realizados mensu...   \n",
      "3   20190601.0  20200901.0  ValorizaciÃ³n de los trabajos realizados mensu...   \n",
      "4   20031001.0  20210101.0  jefe de divisiÃ³n, jefe de ventas, jefe de alm...   \n",
      "\n",
      "  RANGO_SALARIAL  \n",
      "0      2500-2999  \n",
      "1      2500-2999  \n",
      "2      1600-1799  \n",
      "3      1600-1799  \n",
      "4      2500-2999  \n",
      "\n",
      "Archivo guardado exitosamente como 'datos_unidos_completos_59735.csv'\n",
      "\n",
      "Resumen del DataFrame final:\n",
      "Número de filas: 166475\n",
      "Número de columnas: 21\n",
      "\n",
      "Columnas en el DataFrame final: ['ID_POSTULANTE', 'EDAD', 'SEXO', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO', 'UBIGEO', 'ESTADO_CONADIS', 'DOC_ID', 'INSTITUCION', 'GRADO', 'FECHAINICIO_x', 'FECHAFIN_x', 'CARRERA', 'CAUSA', 'DSCORE', 'EMPRESA', 'FECHAINICIO_y', 'FECHAFIN_y', 'DESCRIPCION', 'RANGO_SALARIAL']\n",
      "\n",
      "Valores no nulos en CAUSA y DSCORE:\n",
      "CAUSA no nulos: 166475\n",
      "DSCORE no nulos: 166475\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import datetime as datetime\n",
    "\n",
    "# Enlaces de tus archivos\n",
    "url_discapacidad = 'https://drive.google.com/file/d/1k5tO-1iZ5FGWMJuykYylvbyafiXIMnZ-/view?usp=drive_link'\n",
    "url_educacion = 'https://drive.google.com/file/d/1RBDPcDPG2mCV6dQbUlEJYy8KpnuDPAJH/view?usp=drive_link'\n",
    "url_postulante = 'https://drive.google.com/file/d/1SafIdXKzpLRDJrCQuMAyJh-vE84Zv-P8/view?usp=drive_link'\n",
    "\n",
    "# Función para convertir el enlace de Google Drive en enlace directo\n",
    "def get_drive_link(url):\n",
    "    file_id = url.split('/')[-2]\n",
    "    return f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# 1. Leer los archivos\n",
    "try:\n",
    "    # Leer postulante\n",
    "    df_postulante = pd.read_csv(get_drive_link(url_postulante))\n",
    "    print(\"Archivo de postulante leído correctamente\")\n",
    "\n",
    "    # Leer educación\n",
    "    df_educacion = pd.read_csv(get_drive_link(url_educacion),\n",
    "                              sep=';',\n",
    "                              quotechar='\"',\n",
    "                              encoding='utf-8',\n",
    "                              engine='c',\n",
    "                              on_bad_lines='skip')\n",
    "    print(\"Archivo de educación leído correctamente\")\n",
    "\n",
    "    # Leer discapacidad\n",
    "    df_discapacidad = pd.read_csv(get_drive_link(url_discapacidad))\n",
    "    print(\"Archivo de discapacidad leído correctamente\")\n",
    "\n",
    "    #Leer DATA_EXPERIENCIASLABORALES\n",
    "    df = pd.read_csv('DATA_EXPERIENCIASLABORALES.csv', sep=';')\n",
    "\n",
    "    #imprimir 5 registros de DATA_EXPERIENCIASLABORALES\n",
    "    print(df.head())\n",
    "\n",
    "    # 2. Unir los DataFrames\n",
    "    # Primero unimos postulante con educación\n",
    "    df_merged = pd.merge(df_postulante,\n",
    "                        df_educacion,\n",
    "                        on='ID_POSTULANTE',\n",
    "                        how='left')\n",
    "\n",
    "    # Luego unimos con discapacidad (asegurándonos que las columnas coincidan)\n",
    "    # Renombrar la columna en discapacidad si es necesario\n",
    "    if 'DBIDPOSTULANTE' in df_discapacidad.columns:\n",
    "        df_discapacidad = df_discapacidad.rename(columns={'DBIDPOSTULANTE': 'DOC_ID'})\n",
    "\n",
    "    df_final = pd.merge(df_merged,\n",
    "                       df_discapacidad,\n",
    "                       on='DOC_ID',\n",
    "                       how='left')\n",
    "    \n",
    "    #Unir con DATA_EXPERIENCIASLABORALES\n",
    "    df_final = pd.merge(df_final,\n",
    "                       df,\n",
    "                       on='ID_POSTULANTE',\n",
    "                       how='left')\n",
    "\n",
    "    # 3. Limpieza básica\n",
    "    # Rellenar valores nulos\n",
    "    categorical_columns = ['GRADO', 'CARRERA', 'INSTITUCION', 'DEPARTAMENTO', 'PROVINCIA', 'DISTRITO']\n",
    "    for col in categorical_columns:\n",
    "        df_final[col] = df_final[col].fillna('No especificado')\n",
    "\n",
    "    numeric_columns = ['ESTADO_CONADIS', 'DSCORE']\n",
    "    for col in numeric_columns:\n",
    "        df_final[col] = df_final[col].fillna(0)\n",
    "\n",
    "    # 4. Guardar el resultado\n",
    "    df_final.to_csv('datos_unidos_completos_59735.csv', index=False, encoding='utf-8')\n",
    "    print(\"\\nArchivo guardado exitosamente como 'datos_unidos_completos_59735.csv'\")\n",
    "\n",
    "    # 5. Mostrar resumen\n",
    "    print(\"\\nResumen del DataFrame final:\")\n",
    "    print(f\"Número de filas: {len(df_final)}\")\n",
    "    print(f\"Número de columnas: {len(df_final.columns)}\")\n",
    "    print(\"\\nColumnas en el DataFrame final:\", df_final.columns.tolist())\n",
    "    print(\"\\nValores no nulos en CAUSA y DSCORE:\")\n",
    "    print(\"CAUSA no nulos:\", df_final['CAUSA'].notna().sum())\n",
    "    print(\"DSCORE no nulos:\", df_final['DSCORE'].notna().sum())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error en el proceso:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
